{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author : Keval Kavle\n",
    "#Date : 12-03-2020\n",
    "#Subject : Cloud Computing CS643\n",
    "#Assignment : Programming Assignment-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.sql.functions import ceil, col\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SparkConf().getAll()\n",
    "##### Opening a Spark Session  #####\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"WineQualityPrediction-CS643\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Training Dataset\n",
    "trainDf = spark.read.csv('TrainingDataset.csv',header='true', inferSchema='true', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "#trainDf.select([count(when(isnan(c), c)).alias(c) for c in trainDf.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainDf.show(5,truncate=False)\n",
    "trainDf = trainDf.withColumnRenamed(trainDf.columns[-1],'quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schemaTrain = trainDf.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n"
     ]
    }
   ],
   "source": [
    "##### Test Dataset ####\n",
    "if (sys.argv[1] == '' or sys.argv[1] == \"-f\"):\n",
    "    testpath = \"./\"\n",
    "else :\n",
    "    testpath = sys.argv[1]\n",
    "\n",
    "print(testpath)\n",
    "testpath = \"C:/Users/DELL/Python_Practice/CS643-ProgrammingAssignment2/\"\n",
    "testfile = testpath + 'ValidationDataset.csv'\n",
    "valDf = spark.read.csv(testfile,header='true', schema=schemaTrain, sep=';') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valDf = valDf.withColumnRenamed(valDf.columns[-1],'quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainColumns = [c for c in trainDf.columns  if \"quality\" not in c  ]\n",
    "#trainColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAssembler = VectorAssembler(inputCols=trainColumns,outputCol=\"independentFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTrans = trainAssembler.transform(trainDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = trainTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainTrans.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainTrans.select(\"independentFeatures\").show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardScaler = StandardScaler(inputCol=\"independentFeatures\",outputCol=\"scaledFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = standardScaler.fit(trainTrans).transform(trainTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.show(2,truncate=False)\n",
    "#train.select(\"scaledFeatures\").show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train.show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "valColumns = [c for c in valDf.columns  if \"quality\" not in c  ]\n",
    "#valColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "valAssembler = VectorAssembler(inputCols=valColumns,outputCol=\"independentFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "valTrans = valAssembler.transform(valDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valTrans.select(\"independentFeatures\").show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardScaler = StandardScaler(inputCol=\"independentFeatures\",outputCol=\"scaledFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = standardScaler.fit(valTrans).transform(valTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val = valTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Random Forest  #####\n",
    "rf = RandomForestClassifier(labelCol=\"quality\", featuresCol=\"independentFeatures\",numTrees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write().overwrite().save(\"rfModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(val)\n",
    "#predictions.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.withColumn(\"prediction\", func.round(\"prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Random Forest  Ends #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Linear Regression  #####\n",
    "regressor = LinearRegression(featuresCol=\"independentFeatures\",labelCol=\"quality\")\n",
    "regressor=regressor.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predResults = regressor.evaluate(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predResults = predResults.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.write().overwrite().save(\"lrModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predResults = predResults.withColumn(\"prediction\", func.round(\"prediction\"))\n",
    "#predResults.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Linear Regression Ends ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predResults.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roundoffPrediction =  predictions.select(\"prediction\", func.round(col('prediction')))\n",
    "#roundoffPrediction.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = predictions.withColumn(\"predictionFinal\", roundoffPrediction[1])\n",
    "#predictions = predictions.withColumn(\"prediction\", func.round(\"prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Random Forest Accuarcy - not using this as simple linear regression is giving better results ############\n",
    "evalAcc = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"quality\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evalAcc.evaluate(predictions)\n",
    "\n",
    "##print(\"accuracy Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "\n",
    "transformed_data = model.transform(val)\n",
    "transformed_data = transformed_data.withColumn(\"prediction\", func.round(\"prediction\"))\n",
    "##print(evalAcc.getMetricName(), 'accuracy:', evalAcc.evaluate(transformed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Random Forest f1 - not using this as simple linear regression is giving better results ############\n",
    "evalVal = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"quality\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "accuracy = evalVal.evaluate(predictions)\n",
    "##print(\"f1 Test Error = %g\" % (1.0 - accuracy))\n",
    "transformed_data = model.transform(val)\n",
    "transformed_data = transformed_data.withColumn(\"prediction\", func.round(\"prediction\"))\n",
    "##print(evalVal.getMetricName(), 'accuracy :', evalVal.evaluate(transformed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Linear Regression Accuarcy and f1 ############\n",
    "\n",
    "\n",
    "# Create evaluator\n",
    "evaluatorMulti = MulticlassClassificationEvaluator(labelCol=\"quality\", predictionCol=\"prediction\")\n",
    "\n",
    "# Make predicitons\n",
    "predictionAndTarget = regressor.transform(val).select(\"quality\", \"prediction\")\n",
    "predictionAndTarget = predictionAndTarget.withColumn(\"prediction\", func.round(\"prediction\"))\n",
    "# Get metrics\n",
    "acc = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"accuracy\"})\n",
    "f1 = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"f1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 60.0 %\n",
      "f1 Score : 0.5846181534031478\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy :\" , acc * 100 , \"%\")\n",
    "print(\"f1 Score :\" , f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
